# Example .env for DeepSeek OCR
# Copy this to .env and fill in values for your environment

# Nginx
NGINX_PORT=8080

# VLLM Service (Model path mapping)
# MODEL_HOST_PATH should point to the model directory on the HOST machine
# MODEL_CONTAINER_PATH is where the model will be mounted inside the container
# MODEL_PATH will be set to MODEL_CONTAINER_PATH inside the container (used by the app)
MODEL_HOST_PATH=/path/on/host/to/DeepSeek-OCR
MODEL_CONTAINER_PATH=/models/DeepSeek-OCR

# VLLM server
VLLM_PORT=9000
VLLM_HOST=0.0.0.0

# GPU/ROCm
HIP_VISIBLE_DEVICES=0
CUDA_VISIBLE_DEVICES=
PYTORCH_ROCM_ARCH=gfx1100
VLLM_WORKER_MULTIPROC_METHOD=spawn

# Frontend
FRONTEND_HOST=0.0.0.0
FRONTEND_PORT=5173

# Vite build-time variables
VITE_API_BASE_URL=/api
VITE_APP_VERSION=1.0.0
VITE_ENABLE_WEBCAM=true
VITE_ENABLE_FILE_UPLOAD=true
